{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuf5g2YBf3Q1",
    "outputId": "e9145428-3cce-4f8b-bcf3-4252bf84806a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nolds in /opt/anaconda3/lib/python3.11/site-packages (0.6.3)\n",
      "Requirement already satisfied: future in /opt/anaconda3/lib/python3.11/site-packages (from nolds) (0.18.3)\n",
      "Requirement already satisfied: numpy<3.0,>1.0 in /opt/anaconda3/lib/python3.11/site-packages (from nolds) (1.24.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from nolds) (68.2.2)\n",
      "Requirement already satisfied: hmmlearn in /opt/anaconda3/lib/python3.11/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /opt/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.1.3)\n",
      "Requirement already satisfied: scipy>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from hmmlearn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (2.2.0)\n",
      "Requirement already satisfied: yfinance in /opt/anaconda3/lib/python3.11/site-packages (0.2.54)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (1.24.3)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (3.17.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.11/site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\n",
      "Requirement already satisfied: statsmodels in /opt/anaconda3/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels) (1.15.2)\n",
      "Requirement already satisfied: pandas>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: hurst in /opt/anaconda3/lib/python3.11/site-packages (0.0.5)\n",
      "Requirement already satisfied: ruptures in /opt/anaconda3/lib/python3.11/site-packages (1.1.10)\n",
      "Requirement already satisfied: pandas>=0.18 in /opt/anaconda3/lib/python3.11/site-packages (from hurst) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from hurst) (1.24.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from ruptures) (1.15.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.18->hurst) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.18->hurst) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.18->hurst) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.18->hurst) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nolds\n",
    "!pip install hmmlearn\n",
    "!pip install yfinance\n",
    "!pip install statsmodels\n",
    "!pip install hurst ruptures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8ylebIjH1uim",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "from numpy import *\n",
    "from pylab import plot, show\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wKYZ8J8drzzO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Umcomment this method when running from google colab\n",
    "#def load_data_from_drive(start_date, end_date):\n",
    "  #drive.mount('/content/drive', force_remount=True)\n",
    "  #base_path = Path(\"/content/drive/My Drive/WQU/Capstone/data/parquet_out\")\n",
    "  #dfs = []\n",
    "  #for d in sorted(base_path.iterdir()):\n",
    "      #if d.is_dir() and start_date <= d.name <= end_date:\n",
    "          #dfs.append(pd.read_parquet(d))\n",
    "\n",
    "  #return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def load_data(start_date, end_date):\n",
    "  base_path = Path(\"./data/parquet_out_2\")\n",
    "  dfs = []\n",
    "  for d in sorted(base_path.iterdir()):\n",
    "      if d.is_dir() and start_date <= d.name <= end_date:\n",
    "          dfs.append(pd.read_parquet(d))\n",
    "\n",
    "  return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hTAq9Slrz2K",
    "outputId": "0934f72b-6f53-4143-862d-2a53088e7c5a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        time    symbol bidqty askqty       ltp   atp   ask  \\\n",
      "0  2026-01-01T09:15:00+05:30  NIFTY 50      0      0  26183.50  0.00  0.00   \n",
      "1  2026-01-01T09:16:00+05:30  NIFTY 50      0      0  26194.30  0.00  0.00   \n",
      "2  2026-01-01T09:17:00+05:30  NIFTY 50      0      0  26189.55  0.00  0.00   \n",
      "3  2026-01-01T09:18:00+05:30  NIFTY 50      0      0  26179.50  0.00  0.00   \n",
      "4  2026-01-01T09:19:00+05:30  NIFTY 50      0      0  26167.80  0.00  0.00   \n",
      "\n",
      "    bid oi tot_vol tot_buyqty tot_sellqty ltq                  ltt level2  \\\n",
      "0  0.00  0       0          0           0   0  2026-01-01 09:15:00   None   \n",
      "1  0.00  0       0          0           0   0  2026-01-01 09:16:00   None   \n",
      "2  0.00  0       0          0           0   0  2026-01-01 09:17:00   None   \n",
      "3  0.00  0       0          0           0   0  2026-01-01 09:18:00   None   \n",
      "4  0.00  0       0          0           0   0  2026-01-01 09:19:00   None   \n",
      "\n",
      "  recv_time bcast_time security_id  \n",
      "0         0       None      256265  \n",
      "1         0       None      256265  \n",
      "2         0       None      256265  \n",
      "3         0       None      256265  \n",
      "4         0       None      256265  \n",
      "                           time    symbol bidqty askqty       ltp   atp   ask  \\\n",
      "2995  2026-01-12T15:25:00+05:30  NIFTY 50      0      0  25801.25  0.00  0.00   \n",
      "2996  2026-01-12T15:26:00+05:30  NIFTY 50      0      0  25802.30  0.00  0.00   \n",
      "2997  2026-01-12T15:27:00+05:30  NIFTY 50      0      0  25799.50  0.00  0.00   \n",
      "2998  2026-01-12T15:28:00+05:30  NIFTY 50      0      0  25793.95  0.00  0.00   \n",
      "2999  2026-01-12T15:29:00+05:30  NIFTY 50      0      0  25806.10  0.00  0.00   \n",
      "\n",
      "       bid oi tot_vol tot_buyqty tot_sellqty ltq                  ltt level2  \\\n",
      "2995  0.00  0       0          0           0   0  2026-01-12 15:25:00   None   \n",
      "2996  0.00  0       0          0           0   0  2026-01-12 15:26:00   None   \n",
      "2997  0.00  0       0          0           0   0  2026-01-12 15:27:00   None   \n",
      "2998  0.00  0       0          0           0   0  2026-01-12 15:28:00   None   \n",
      "2999  0.00  0       0          0           0   0  2026-01-12 15:29:00   None   \n",
      "\n",
      "     recv_time bcast_time security_id  \n",
      "2995         0       None      256265  \n",
      "2996         0       None      256265  \n",
      "2997         0       None      256265  \n",
      "2998         0       None      256265  \n",
      "2999         0       None      256265  \n"
     ]
    }
   ],
   "source": [
    "df = load_data(\"2026-01-01\", \"2026-01-12\")\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1cIspFzxJbS"
   },
   "source": [
    "**Function to get 1 min data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZAQu9tjbehpb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_intraday_minutes(day_df):\n",
    "    day = day_df.index[0].date()\n",
    "    full_index = pd.date_range(\n",
    "        start=pd.Timestamp(f\"{day} 09:15\"),\n",
    "        end=pd.Timestamp(f\"{day} 15:30\"),\n",
    "        freq=\"1min\"\n",
    "    )\n",
    "    return day_df.reindex(full_index).ffill()\n",
    "\n",
    "def get_data_one_min_freq(start_date, end_date):\n",
    "  df = load_data(start_date=start_date, end_date=end_date)\n",
    "  df.drop(columns=['time', 'symbol', 'security_id', 'level2', 'bcast_time'], inplace=True)\n",
    "  df['ltt'] = pd.to_datetime(df['ltt'])\n",
    "  df = df.sort_values('ltt').set_index('ltt')\n",
    "  df_1min = (\n",
    "    df\n",
    "    .groupby(df.index.date, group_keys=False)\n",
    "    .apply(fill_intraday_minutes)\n",
    "  )\n",
    "  return df_1min\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlnsobDGmZYm",
    "outputId": "052ccd48-c301-4651-9709-b6d2d4dd2ea2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:01:00    3000\n",
      "0 days 17:45:00       5\n",
      "2 days 17:45:00       2\n",
      "Name: count, dtype: int64\n",
      "376    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_1min = get_data_one_min_freq(\"2026-01-01\", \"2026-01-12\")\n",
    "print(df_1min.index.to_series().diff().value_counts())\n",
    "print(df_1min.groupby(df_1min.index.date).size().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDv3FDaSxR8l"
   },
   "source": [
    "**Function to get 5 mins data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "H3qmGA71qvM8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_intraday_5min(day_df):\n",
    "    day = day_df.index[0].date()\n",
    "\n",
    "    # Create fixed 5-min intraday grid\n",
    "    full_index = pd.date_range(\n",
    "        start=pd.Timestamp(f\"{day} 09:15\"),\n",
    "        end=pd.Timestamp(f\"{day} 15:30\"),\n",
    "        freq=\"5min\"\n",
    "    )\n",
    "\n",
    "    # Resample to 5-min bars (last price per bar)\n",
    "    day_5min = (\n",
    "        day_df\n",
    "        .resample(\"5min\")\n",
    "        .last()\n",
    "    )\n",
    "\n",
    "    # Reindex to full grid and forward-fill within day\n",
    "    return day_5min.reindex(full_index).ffill()\n",
    "\n",
    "\n",
    "def get_data_5min_freq(start_date, end_date):\n",
    "    df = load_data(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    df.drop(\n",
    "        columns=['time', 'symbol', 'security_id', 'level2', 'bcast_time'],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    df['ltt'] = pd.to_datetime(df['ltt'])\n",
    "    df = df.sort_values('ltt').set_index('ltt')\n",
    "\n",
    "    df = df[~df.index.isna()]\n",
    "\n",
    "    df_5min = (\n",
    "        df\n",
    "        .groupby(df.index.date, group_keys=False)\n",
    "        .apply(fill_intraday_5min)\n",
    "    )\n",
    "\n",
    "    return df_5min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2Np8Z6YqvP3",
    "outputId": "9a4f8251-a99a-4b1f-fbb5-5fa908de9af1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:05:00    600\n",
      "0 days 17:45:00      5\n",
      "2 days 17:45:00      2\n",
      "Name: count, dtype: int64\n",
      "76    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_5min = get_data_5min_freq(\"2026-01-01\", \"2026-01-12\")\n",
    "print(df_5min.index.to_series().diff().value_counts())\n",
    "print(df_5min.groupby(df_5min.index.date).size().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Onm7r9KUqvS9",
    "outputId": "ea5d87c4-7434-4391-d685-5d596c829a50",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026-01-01    76\n",
       "2026-01-02    76\n",
       "2026-01-05    76\n",
       "2026-01-06    76\n",
       "2026-01-07    76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5min.groupby(df_5min.index.date).size().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfQ7dSJJx2ZU"
   },
   "source": [
    "**Function to get 15 mins data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "sVPVN-_Rx3WF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_intraday_15min(day_df):\n",
    "    day = day_df.index[0].date()\n",
    "\n",
    "    # Create fixed 15-min intraday grid\n",
    "    full_index = pd.date_range(\n",
    "        start=pd.Timestamp(f\"{day} 09:15\"),\n",
    "        end=pd.Timestamp(f\"{day} 15:30\"),\n",
    "        freq=\"15min\"\n",
    "    )\n",
    "\n",
    "    # Resample to 5-min bars (last price per bar)\n",
    "    day_15min = (\n",
    "        day_df\n",
    "        .resample(\"15min\")\n",
    "        .last()\n",
    "    )\n",
    "\n",
    "    # Reindex to full grid and forward-fill within day\n",
    "    return day_15min.reindex(full_index).ffill()\n",
    "\n",
    "\n",
    "def get_data_15min_freq(start_date, end_date):\n",
    "    df = load_data(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    df.drop(\n",
    "        columns=['time', 'symbol', 'security_id', 'level2', 'bcast_time'],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    df['ltt'] = pd.to_datetime(df['ltt'])\n",
    "    df = df.sort_values('ltt').set_index('ltt')\n",
    "\n",
    "    df = df[~df.index.isna()]\n",
    "\n",
    "    df_15min = (\n",
    "        df\n",
    "        .groupby(df.index.date, group_keys=False)\n",
    "        .apply(fill_intraday_15min)\n",
    "    )\n",
    "\n",
    "    return df_15min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hLw3YeWyDyg",
    "outputId": "f74afeb1-49cf-4306-f840-f0025300aa38",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 00:15:00    200\n",
      "0 days 17:45:00      5\n",
      "2 days 17:45:00      2\n",
      "Name: count, dtype: int64\n",
      "26    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_15min = get_data_15min_freq(\"2026-01-01\", \"2026-01-12\")\n",
    "print(df_15min.index.to_series().diff().value_counts())\n",
    "print(df_15min.groupby(df_15min.index.date).size().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Jw-qLN0myow0",
    "outputId": "6d535eea-4e4c-482d-ae09-68a1ec0aed6b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidqty</th>\n",
       "      <th>askqty</th>\n",
       "      <th>ltp</th>\n",
       "      <th>atp</th>\n",
       "      <th>ask</th>\n",
       "      <th>bid</th>\n",
       "      <th>oi</th>\n",
       "      <th>tot_vol</th>\n",
       "      <th>tot_buyqty</th>\n",
       "      <th>tot_sellqty</th>\n",
       "      <th>ltq</th>\n",
       "      <th>recv_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-12 14:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25760.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 14:45:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25810.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 15:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25778.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 15:15:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25806.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 15:30:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25806.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bidqty askqty       ltp   atp   ask   bid oi tot_vol  \\\n",
       "2026-01-12 14:30:00      0      0  25760.80  0.00  0.00  0.00  0       0   \n",
       "2026-01-12 14:45:00      0      0  25810.45  0.00  0.00  0.00  0       0   \n",
       "2026-01-12 15:00:00      0      0  25778.50  0.00  0.00  0.00  0       0   \n",
       "2026-01-12 15:15:00      0      0  25806.10  0.00  0.00  0.00  0       0   \n",
       "2026-01-12 15:30:00      0      0  25806.10  0.00  0.00  0.00  0       0   \n",
       "\n",
       "                    tot_buyqty tot_sellqty ltq recv_time  \n",
       "2026-01-12 14:30:00          0           0   0         0  \n",
       "2026-01-12 14:45:00          0           0   0         0  \n",
       "2026-01-12 15:00:00          0           0   0         0  \n",
       "2026-01-12 15:15:00          0           0   0         0  \n",
       "2026-01-12 15:30:00          0           0   0         0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_15min.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "T2WjYFEgyD6n",
    "outputId": "a25171e2-611f-4ada-a387-18fa05f9ed53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026-01-01    26\n",
       "2026-01-02    26\n",
       "2026-01-05    26\n",
       "2026-01-06    26\n",
       "2026-01-07    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_15min.groupby(df_15min.index.date).size().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vk-T51rbzfMK"
   },
   "source": [
    "Function to get 60 mins data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "QBVtfrU9zcZ8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUMERIC_COLS = [\n",
    "    \"tot_vol\", \"ask\", \"bid\", \"oi\", \"askqty\", \"bidqty\",\n",
    "    \"tot_buyqty\", \"tot_sellqty\", \"ltq\", \"atp\"\n",
    "]\n",
    "\n",
    "for col in NUMERIC_COLS:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "PRICE_COL = \"ltp\"\n",
    "VOLUME_COL = \"tot_vol\"\n",
    "\n",
    "LAST_COLS = [\n",
    "    \"ask\", \"bid\", \"oi\", \"askqty\", \"bidqty\",\n",
    "    \"tot_buyqty\", \"tot_sellqty\", \"ltq\", \"atp\", \"recv_time\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def build_agg_dict(df):\n",
    "  agg = {\n",
    "      PRICE_COL: [\"first\", \"max\", \"min\", \"last\"],\n",
    "      VOLUME_COL: \"sum\"\n",
    "  }\n",
    "\n",
    "  for col in LAST_COLS:\n",
    "    if col in df.columns:\n",
    "      agg[col] = \"last\"\n",
    "  return agg\n",
    "\n",
    "\n",
    "def get_data_60min_freq(start_date, end_date):\n",
    "    df = load_data(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    df.drop(\n",
    "        columns=['time', 'symbol', 'security_id', 'level2', 'bcast_time'],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "\n",
    "    NUMERIC_COLS = [\n",
    "        \"tot_vol\", \"ask\", \"bid\", \"oi\",\n",
    "        \"askqty\", \"bidqty\", \"tot_buyqty\",\n",
    "        \"tot_sellqty\", \"ltq\", \"atp\"\n",
    "    ]\n",
    "\n",
    "    for col in NUMERIC_COLS:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df['ltt'] = pd.to_datetime(df['ltt'], errors=\"coerce\")\n",
    "    df = df.sort_values('ltt').set_index('ltt')\n",
    "    df = df[~df.index.isna()]\n",
    "\n",
    "    df_60min = (\n",
    "        df\n",
    "        .groupby(df.index.date, group_keys=False)\n",
    "        .apply(fill_intraday_60min)\n",
    "    )\n",
    "\n",
    "    return df_60min\n",
    "\n",
    "\n",
    "def fill_intraday_60min(day_df):\n",
    "    day = day_df.index[0].date()\n",
    "\n",
    "    full_index = pd.date_range(\n",
    "        start=pd.Timestamp(f\"{day} 09:15\"),\n",
    "        end=pd.Timestamp(f\"{day} 15:15\"),\n",
    "        freq=\"60min\"\n",
    "    )\n",
    "\n",
    "    agg_dict = build_agg_dict(day_df)\n",
    "\n",
    "    day_60min = (\n",
    "    day_df\n",
    "    .resample(\n",
    "        \"60min\",\n",
    "        origin=pd.Timestamp(f\"{day} 09:15\"),\n",
    "        label=\"right\",\n",
    "        closed=\"right\"\n",
    "    )\n",
    "    .agg(agg_dict)\n",
    "    )\n",
    "\n",
    "    day_60min.columns = [\n",
    "        f\"{c[0]}_{c[1]}\" if isinstance(c, tuple) else c\n",
    "        for c in day_60min.columns\n",
    "    ]\n",
    "\n",
    "    return day_60min.reindex(full_index).ffill()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qD2HW55Iz2E9",
    "outputId": "ec5a483a-e138-4792-e081-88ff8d3f862c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 days 01:00:00    48\n",
      "0 days 18:00:00     5\n",
      "2 days 18:00:00     2\n",
      "Name: count, dtype: int64\n",
      "7    8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_60min = get_data_60min_freq(\"2026-01-01\", \"2026-01-12\")\n",
    "print(df_60min.index.to_series().diff().value_counts())\n",
    "print(df_60min.groupby(df_60min.index.date).size().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "0xEmgFQo0IfH",
    "outputId": "40d1e173-d990-4aa7-dcec-dc3904298688",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ltp_first</th>\n",
       "      <th>ltp_max</th>\n",
       "      <th>ltp_min</th>\n",
       "      <th>ltp_last</th>\n",
       "      <th>tot_vol_sum</th>\n",
       "      <th>ask_last</th>\n",
       "      <th>bid_last</th>\n",
       "      <th>oi_last</th>\n",
       "      <th>askqty_last</th>\n",
       "      <th>bidqty_last</th>\n",
       "      <th>tot_buyqty_last</th>\n",
       "      <th>tot_sellqty_last</th>\n",
       "      <th>ltq_last</th>\n",
       "      <th>atp_last</th>\n",
       "      <th>recv_time_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-12 11:15:00</th>\n",
       "      <td>25550.40</td>\n",
       "      <td>25595.30</td>\n",
       "      <td>25528.80</td>\n",
       "      <td>25528.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 12:15:00</th>\n",
       "      <td>25526.15</td>\n",
       "      <td>25578.30</td>\n",
       "      <td>25475.00</td>\n",
       "      <td>25577.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 13:15:00</th>\n",
       "      <td>25583.40</td>\n",
       "      <td>25732.20</td>\n",
       "      <td>25583.40</td>\n",
       "      <td>25725.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 14:15:00</th>\n",
       "      <td>25726.60</td>\n",
       "      <td>25751.55</td>\n",
       "      <td>25689.05</td>\n",
       "      <td>25729.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-12 15:15:00</th>\n",
       "      <td>25734.05</td>\n",
       "      <td>25812.45</td>\n",
       "      <td>25705.70</td>\n",
       "      <td>25784.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ltp_first   ltp_max   ltp_min  ltp_last  tot_vol_sum  \\\n",
       "time                                                                       \n",
       "2026-01-12 11:15:00  25550.40  25595.30  25528.80  25528.80            0   \n",
       "2026-01-12 12:15:00  25526.15  25578.30  25475.00  25577.45            0   \n",
       "2026-01-12 13:15:00  25583.40  25732.20  25583.40  25725.15            0   \n",
       "2026-01-12 14:15:00  25726.60  25751.55  25689.05  25729.15            0   \n",
       "2026-01-12 15:15:00  25734.05  25812.45  25705.70  25784.05            0   \n",
       "\n",
       "                     ask_last  bid_last  oi_last  askqty_last  bidqty_last  \\\n",
       "time                                                                         \n",
       "2026-01-12 11:15:00       0.0       0.0        0            0            0   \n",
       "2026-01-12 12:15:00       0.0       0.0        0            0            0   \n",
       "2026-01-12 13:15:00       0.0       0.0        0            0            0   \n",
       "2026-01-12 14:15:00       0.0       0.0        0            0            0   \n",
       "2026-01-12 15:15:00       0.0       0.0        0            0            0   \n",
       "\n",
       "                     tot_buyqty_last  tot_sellqty_last  ltq_last  atp_last  \\\n",
       "time                                                                         \n",
       "2026-01-12 11:15:00                0                 0         0       0.0   \n",
       "2026-01-12 12:15:00                0                 0         0       0.0   \n",
       "2026-01-12 13:15:00                0                 0         0       0.0   \n",
       "2026-01-12 14:15:00                0                 0         0       0.0   \n",
       "2026-01-12 15:15:00                0                 0         0       0.0   \n",
       "\n",
       "                    recv_time_last  \n",
       "time                                \n",
       "2026-01-12 11:15:00              0  \n",
       "2026-01-12 12:15:00              0  \n",
       "2026-01-12 13:15:00              0  \n",
       "2026-01-12 14:15:00              0  \n",
       "2026-01-12 15:15:00              0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_60min.index.name = 'time'\n",
    "df_60min.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Returns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADF pass-fraction      0.993239\n",
       "KPSS pass-fraction     0.957173\n",
       "LB p-lag10             0.984842\n",
       "LB p-lag20             0.999973\n",
       "Kurtosis>2 fraction    0.725304\n",
       "Hill alpha             2.981839\n",
       "Hurst (rv)             0.679603\n",
       "Breakpoints            0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MARKET-DYNAMICS  GATE: FAIL ❌\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "#  MARKET-DYNAMICS  –  Diagnostics  (quiet & threshold-tunable)\n",
    "# ===============================================================\n",
    "import numpy as np, pandas as pd, warnings\n",
    "from statsmodels.tsa.stattools    import adfuller, kpss\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
    "from scipy.stats  import kurtosis\n",
    "from hurst        import compute_Hc\n",
    "import ruptures as rpt\n",
    "\n",
    "# ── silence spammy warnings ─────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\", category=InterpolationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
    "                        module=\"statsmodels.tsa.stattools\")\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")\n",
    "\n",
    "# ── load price series (ltp) ────────────────────────────────────\n",
    "df_1m = get_data_one_min_freq(\"2016-01-01\", \"2025-12-31\")\n",
    "if \"time\" in df_1m.columns:\n",
    "    df_1m = df_1m.set_index(\"time\")\n",
    "df_1m.index = (df_1m.index.tz_localize(\"Asia/Kolkata\")\n",
    "               if df_1m.index.tz is None\n",
    "               else df_1m.index.tz_convert(\"Asia/Kolkata\"))\n",
    "close   = pd.to_numeric(df_1m[\"ltp\"], errors=\"coerce\").dropna()\n",
    "returns = close.pct_change().dropna()\n",
    "\n",
    "# ── helpers ────────────────────────────────────────────────────\n",
    "WINDOW = 250\n",
    "roll_p = lambda s, fn: s.rolling(WINDOW).apply(lambda x: fn(x)[1], raw=False)\n",
    "\n",
    "adf_p  = roll_p(returns, lambda x: adfuller(x, maxlag=12))\n",
    "kpss_p = roll_p(returns, lambda x: kpss(x, nlags=\"auto\"))\n",
    "lb_df  = acorr_ljungbox(returns**2, lags=[10, 20], return_df=True)\n",
    "\n",
    "kurt_ex  = returns.rolling(WINDOW).apply(\n",
    "    lambda x: kurtosis(x, fisher=True, bias=False), raw=False\n",
    ")\n",
    "tail = returns.abs().sort_values(ascending=False)\n",
    "k    = max(int(0.05 * len(tail)), 1)\n",
    "hill_alpha = k / np.log(tail.iloc[:k] / tail.iloc[k-1]).sum()\n",
    "\n",
    "rv  = returns.rolling(30).std().dropna()\n",
    "H, *_ = compute_Hc(rv, kind=\"change\", simplified=True)\n",
    "n_breaks = len(rpt.Binseg(\"l2\").fit(returns.values).predict(pen=10)) - 1\n",
    "\n",
    "# ── summary ────────────────────────────────────────────────────\n",
    "summary = pd.Series({\n",
    "    \"ADF pass-fraction\"     : (adf_p  < 0.05).mean(),\n",
    "    \"KPSS pass-fraction\"    : (kpss_p > 0.05).mean(),\n",
    "    \"LB p-lag10\"            : lb_df.loc[10, \"lb_pvalue\"],\n",
    "    \"LB p-lag20\"            : lb_df.loc[20, \"lb_pvalue\"],\n",
    "    \"Kurtosis>2 fraction\"   : (kurt_ex > 2).mean(),\n",
    "    \"Hill alpha\"            : hill_alpha,\n",
    "    \"Hurst (rv)\"            : H,\n",
    "    \"Breakpoints\"           : n_breaks\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# ── gate rules (tweakable) ─────────────────────────────────────\n",
    "LB_THRESHOLD   = 0.10   # raise from 0.05 if clustering is weak\n",
    "HURST_MIN      = 0.55\n",
    "\n",
    "gate_pass = (\n",
    "    summary[\"ADF pass-fraction\"]   >= 0.70 and\n",
    "    summary[\"KPSS pass-fraction\"]  >= 0.70 and\n",
    "    summary[\"LB p-lag10\"] < LB_THRESHOLD and\n",
    "    summary[\"LB p-lag20\"] < LB_THRESHOLD and\n",
    "    (summary[\"Kurtosis>2 fraction\"] > 0.30 or summary[\"Hill alpha\"] < 4) and\n",
    "    summary[\"Hurst (rv)\"] > HURST_MIN\n",
    ")\n",
    "\n",
    "print(\"\\nMARKET-DYNAMICS  GATE:\", \"PASS ✅\" if gate_pass else \"FAIL ❌\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '≈' (U+2248) (3349118641.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[65], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    | **ADF pass-fraction ≈ 0.99**       | Minute-to-minute returns almost never exhibit a unit root ⇒ *mean is locally stable*. You can compute rolling z-scores without first-difference pre-whitening. |                             |                                                                                 |\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '≈' (U+2248)\n"
     ]
    }
   ],
   "source": [
    "# Insights of this diagnostics: \n",
    "# | Metric                             | Result                                                                                                                                                         | What it means (practically) |                                                                                 |\n",
    "# | ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------- | ------------------------------------------------------------------------------- |\n",
    "# | **ADF pass-fraction ≈ 0.99**       | Minute-to-minute returns almost never exhibit a unit root ⇒ *mean is locally stable*. You can compute rolling z-scores without first-difference pre-whitening. |                             |                                                                                 |\n",
    "# | **KPSS pass-fraction ≈ 0.96**      | Trend non-stationarity is rarely detected ⇒ no long deterministic trend inside single trading days.                                                            |                             |                                                                                 |\n",
    "# | **Excess-kurtosis windows ≈ 72 %** | 1-min returns have fat tails most of the time ⇒ intraday shocks are common → risk shell needs fat-tail-aware stops.                                            |                             |                                                                                 |\n",
    "# | **Hill tail-α ≈ 2.98**             | Tail exponent < 4 → VaR based on Gaussian variance will *seriously* under-state risk; stick with EVT-style tail metrics.                                       |                             |                                                                                 |\n",
    "# | **Hurst (rv) ≈ 0.68**              | Realised volatility is *persistent* (long memory) even though raw returns aren’t. Good news: a latent-vol regime model is still justified.                     |                             |                                                                                 |\n",
    "# | **Breakpoints = 0**                | No large structural mean/variance breaks across the full 2016-2025 window at 1-min granularity.                                                                |                             |                                                                                 |\n",
    "# | **Ljung-Box on                     | r                                                                                                                                                              | ²: p≈ 1**                   | Classic ARCH-style short-lag clustering at 10/20 minutes is essentially absent. |\n",
    "\n",
    "\n",
    "\n",
    "# Key takeaway:\n",
    "# Volatility persistence exists (Hurst > 0.5), but it is not showing up as rapid autocorrelation in |r|² at the 10–20 minute lags.\n",
    "# So our original Ljung-Box gate is too strict for this data.\n",
    "\n",
    "# Deeper exploration roadmap (choose in parallel, not sequentially)\n",
    "\n",
    "# | Path                                                                          | What we compute next                                                                                                                                            | Insight we expect                                                        | Impact downstream                                                                                           |                                                    |                                                                  |\n",
    "# | ----------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------- | -------------------------------------------------- | ---------------------------------------------------------------- |\n",
    "# | **A. Time-segmented analysis**<br>(“are there hot months?”)                   | • Re-run Ljung-Box on                                                                                                                                           | r                                                                        | ² **month-by-month**.<br>• Flag months where p < 0.05.<br>• Overlay with macro events (e.g., COVID crash).  | Clustering may be episodic (high-vol months only). | HMM can incorporate a *state-specific* vol-clustering component. |\n",
    "# | **B. Lag & horizon sweep**<br>(“maybe clustering sits at 1–5 min, not 10–20”) | • Compute Ljung-Box for lags [1, 5, 30, 60].<br>• Repeat on **5-min returns** to see if smoothing reveals autocorr.<br>• Plot p-value heat-map (lag × horizon). | Pinpoint where volatility autocorr actually lives.                       | Choose the **feature sampling rate** (1-min vs 5-min) that shows strongest clustering for regime detection. |                                                    |                                                                  |\n",
    "# | **C. Longer historical window**                                               | • If you have pre-2016 data, extend sample to 2010.<br>• Re-run entire Market-Dynamics block.                                                                   | Older crises (e.g., 2013 taper tantrum) often exhibit strong clustering. | Confirms whether “quiet vol-of-vol” is just a recent phenomenon.                                            |                                                    |                                                                  |\n",
    "# | **D. Higher aggregation** *(optional but cheap)*                              | • Aggregate to **15-min and 60-min** bars.<br>• Repeat ADF/KPSS, Hurst on realised vol at those horizons.                                                       | See how persistence & tails change with scale.                           | Helps decide which horizon is most predictive for mean-reversion signals.                                   |                                                    |                                                                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further POA:\n",
    "# | Path                                         | Goal                                                      | Tweak / Approach                                                                                                        | Evidence to collect                                                              | Down-stream implication                                                                                          |\n",
    "# | -------------------------------------------- | --------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- |\n",
    "# | **A – Lag Sweep on 1-min Returns**           | Find the *true* short-horizon volatility-clustering lag.  | Replace `lags=[10,20]` with `lags=[1,2,5,10,20,30,60]` in Ljung-Box call.<br> (`acorr_ljungbox(returns**2, lags=lags)`) | • Table/plot of p-values vs lag.<br>• “First lag where p < 0.05.”                | Choose `VOL_LAG_FEATURE` for HMM; if clustering appears at lag 1–5, no need to resample.                         |\n",
    "# | **B – Horizon Sweep (5-min & 15-min)**       | Test if clustering emerges after de-noising.              | Resample price to 5-min & 15-min bars (`last()`), recompute returns → run Ljung-Box at lags [1,4,12].                   | Heat-map (horizon × lag) of p-values.                                            | If clustering strongest at 5-min lag-1 → compute **realised-vol over 5 min** for regime model instead of 1-min.  |\n",
    "# | **C – Month-by-Month Episodes**              | Detect episodic clustering (e.g., crisis months).         | Loop over calendar months; run Ljung-Box (lag 1–5) per month; flag months with p < 0.05.                                | CSV: month, LB-p.<br>Overlay of flagged months vs VIX spikes or NIFTY drawdowns. | HMM can include “crisis state” priors; walk-forward folds can align with flagged episodes.                       |\n",
    "# | **D – Longer History Extension**             | See if older high-stress eras exhibit clustering.         | Append 2010-2015 data (if available) and re-run Path A.                                                                 | Same metrics as Path A but on extended sample.                                   | Confirms whether weak clustering is a *recent* phenomenon; if not, regime model can condition on macro epoch.    |\n",
    "# | **E – Higher Aggregation for Hurst & Tails** | Understand scale-dependency of persistence and fat tails. | Aggregate to 30-min & 60-min bars; recompute Hurst on realised-vol and Hill α.  \n",
    "                                                                                                                                              \n",
    "#                                                                                                                                               Execution order (recommended)\n",
    "\n",
    "# Path A – fastest insight; one‐line change.\n",
    "\n",
    "# Path B – also cheap; often reveals hidden clustering.\n",
    "\n",
    "# Path C – loop, but quick once functions are written.\n",
    "\n",
    "# Path E – five-minute task; optional but informative.\n",
    "\n",
    "# Path D – only if older data is readily at hand.\n",
    "\n",
    "    \n",
    "# Once you run Path A & B you will know whether to:\n",
    "\n",
    "# loosen the Ljung-Box gate,\n",
    "\n",
    "# resample features to 5-min, or\n",
    "\n",
    "# keep clustering out of the regime model entirely.| Line chart: Hurst vs bar size; Hill α vs bar size.                               \n",
    "#     | Helps decide if **mean-reversion signal** should be built on 15-min or 60-min deviations instead of 1-min noise. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag (min)</th>\n",
       "      <th>LB p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.305201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.473647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.615018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.849991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.984842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.999048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lag (min)  LB p-value\n",
       "0          1    0.305201\n",
       "1          2    0.473647\n",
       "2          3    0.615018\n",
       "3          5    0.849991\n",
       "4         10    0.984842\n",
       "5         15    0.999048\n",
       "6         20    0.999973\n",
       "7         30    1.000000\n",
       "8         60    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ℹ️  No Ljung-Box p-value below 0.05 for lags 1–60 min\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────\n",
    "#  PATH A  –  Lag Sweep on 1-min Returns\n",
    "#      Goal: find the lags where volatility clustering (ARCH-type)\n",
    "#            is statistically significant.\n",
    "# ────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# 1-min absolute-squared returns\n",
    "lags  = [1, 2, 3, 5, 10, 15, 20, 30, 60]       # minutes\n",
    "lb_df = acorr_ljungbox(returns**2, lags=lags, return_df=True)\n",
    "\n",
    "# Assemble p-values in a tidy DataFrame\n",
    "lag_sweep = pd.DataFrame({\n",
    "    \"Lag (min)\" : lags,\n",
    "    \"LB p-value\": lb_df[\"lb_pvalue\"].values\n",
    "})\n",
    "display(lag_sweep)\n",
    "\n",
    "# Highlight the first lag that shows clustering\n",
    "first_sig = lag_sweep.loc[lag_sweep[\"LB p-value\"] < 0.05]\n",
    "if not first_sig.empty:\n",
    "    print(f\"\\n✅ Volatility clustering detected at lag {first_sig.iloc[0,0]}-min \"\n",
    "          f\"(p = {first_sig.iloc[0,1]:.4f})\")\n",
    "else:\n",
    "    print(\"\\nℹ️  No Ljung-Box p-value below 0.05 for lags 1–60 min\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What this means\n",
    "\n",
    "# Minute-level volatility is almost memory-less – shocks fade within 60 seconds.\n",
    "\n",
    "# The long-memory signal you saw in Hurst (rv ≈ 0.68) must be driven by lower-frequency co-movement, not rapid ARCH feedback.\n",
    "\n",
    "# A hidden-volatility HMM is still justified, but it should consume lower-frequency realised-vol (e.g., 5-min or 15-min) rather than raw |r|² at 1-min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horizon</th>\n",
       "      <th>Lag(mult)</th>\n",
       "      <th>LB p-val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5min</td>\n",
       "      <td>1</td>\n",
       "      <td>7.531745e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5min</td>\n",
       "      <td>2</td>\n",
       "      <td>5.169874e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5min</td>\n",
       "      <td>4</td>\n",
       "      <td>9.799659e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5min</td>\n",
       "      <td>8</td>\n",
       "      <td>4.023022e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15min</td>\n",
       "      <td>1</td>\n",
       "      <td>1.367539e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15min</td>\n",
       "      <td>2</td>\n",
       "      <td>4.825258e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15min</td>\n",
       "      <td>3</td>\n",
       "      <td>1.928460e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15min</td>\n",
       "      <td>4</td>\n",
       "      <td>2.712608e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Horizon  Lag(mult)      LB p-val\n",
       "0    5min          1  7.531745e-08\n",
       "1    5min          2  5.169874e-10\n",
       "2    5min          4  9.799659e-15\n",
       "3    5min          8  4.023022e-18\n",
       "4   15min          1  1.367539e-04\n",
       "5   15min          2  4.825258e-05\n",
       "6   15min          3  1.928460e-06\n",
       "7   15min          4  2.712608e-06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 5min: clustering at lag 1×5min (p = 0.0000)\n",
      "✅ 15min: clustering at lag 1×15min (p = 0.0001)\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "#  PATH B – Horizon Sweep (5-min & 15-min returns)\n",
    "#      Goal: see whether volatility clustering appears after\n",
    "#            smoothing 1-min noise.\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import pandas as pd\n",
    "\n",
    "horizons   = {\"5min\": [1, 2, 4, 8],   # lags in multiples of the horizon\n",
    "              \"15min\": [1, 2, 3, 4]}  # (e.g., 4 × 15 min = 1 hour)\n",
    "\n",
    "results = []\n",
    "\n",
    "for tf, lags in horizons.items():\n",
    "    # resample close prices to tf bars and compute returns\n",
    "    r_tf = close.resample(tf).last().pct_change().dropna()\n",
    "    \n",
    "    lb_df = acorr_ljungbox(r_tf**2, lags=lags, return_df=True, model_df=0)\n",
    "    \n",
    "    res = pd.DataFrame({\n",
    "        \"Horizon\"   : tf,\n",
    "        \"Lag(mult)\" : lags,\n",
    "        \"LB p-val\"  : lb_df[\"lb_pvalue\"].values\n",
    "    })\n",
    "    results.append(res)\n",
    "\n",
    "lb_sweep_tf = pd.concat(results, ignore_index=True)\n",
    "display(lb_sweep_tf)\n",
    "\n",
    "# Flag first significant clustering per horizon\n",
    "for tf in lb_sweep_tf[\"Horizon\"].unique():\n",
    "    sub = lb_sweep_tf[lb_sweep_tf[\"Horizon\"] == tf]\n",
    "    sig = sub[sub[\"LB p-val\"] < 0.05]\n",
    "    if not sig.empty:\n",
    "        lag = sig.iloc[0][\"Lag(mult)\"]\n",
    "        p   = sig.iloc[0][\"LB p-val\"]\n",
    "        print(f\"✅ {tf}: clustering at lag {lag}×{tf} (p = {p:.4f})\")\n",
    "    else:\n",
    "        print(f\"ℹ️  {tf}: no significant clustering (p < 0.05) up to max lag tested\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path B findings — volatility clustering emerges once we look at coarser bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Horizon         | First significant lag | Actual clock lag | p-value    |\n",
    "# | --------------- | --------------------- | ---------------- | ---------- |\n",
    "# | **5-min bars**  | lag-1                 | **5 minutes**    | 7.5 × 10⁻⁸ |\n",
    "# # | **15-min bars** | lag-1                 | **15 minutes**   | 1.3 × 10⁻⁴ |\n",
    "\n",
    "\n",
    "# Every longer lag you tested (5-min × 2,4,8 and 15-min × 2-4) is even more significant.\n",
    "# Interpretation:\n",
    "\n",
    "# Minute-to-minute noise masks clustering.\n",
    "# After smoothing into 5- and 15-minute bars, classic ARCH-type feedback appears immediately (lag-1).\n",
    "\n",
    "# Clustering is strongest at the coarsest resolution you need for trading decisions:\n",
    "# 5-minute lag-1 is ideal for intraday mean-reversion; 15-minute lag-1 confirms the effect persists at a higher scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Judgment for further path \n",
    "\n",
    "# | Design element           | Decision based on results                                                                                                                                              |\n",
    "# | ------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "# | **Realised-vol feature** | Compute on **rolling 5-minute returns** (better signal-to-noise).                                                                                                      |\n",
    "# | **Vol-regime HMM input** | Use 5-min realised-vol *and* include **lag-1 autocorrelation** as an auxiliary observation.                                                                            |\n",
    "# | **Gate update**          | Replace 1-min Ljung-Box test with **5-min lag-1** (p < 0.05) as the pass condition.                                                                                    |\n",
    "# | **Signal sampling**      | Keep execution on 1-min bars (to control slippage) but evaluate regime & risk every 5 minutes.                                                                         |\n",
    "# | **Documentation**        | Note: “Volatility clustering is absent at 1-minute scale but pronounced at 5- and 15-minute scales; regime filters therefore operate on 5-minute realised volatility.” |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market-Dynamics Gate” cell—updated for 5-minute clustering (Path B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# MARKET-DYNAMICS  –  Diagnostics Gate  (5-min clustering version)\n",
    "# =============================================================\n",
    "import numpy as np, pandas as pd, warnings\n",
    "from statsmodels.tsa.stattools    import adfuller, kpss\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
    "from scipy.stats  import kurtosis\n",
    "from hurst        import compute_Hc\n",
    "import ruptures as rpt\n",
    "\n",
    "# ── Silence warning spam ──────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\", category=InterpolationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
    "                        module=\"statsmodels.tsa.stattools\")\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")\n",
    "\n",
    "# ── 1) Load 1-minute price series (ltp) ───────────────────────\n",
    "df_1m = get_data_one_min_freq(\"2016-01-01\", \"2025-12-31\")\n",
    "if \"time\" in df_1m.columns:\n",
    "    df_1m = df_1m.set_index(\"time\")\n",
    "df_1m.index = (df_1m.index.tz_localize(\"Asia/Kolkata\")\n",
    "               if df_1m.index.tz is None\n",
    "               else df_1m.index.tz_convert(\"Asia/Kolkata\"))\n",
    "close   = pd.to_numeric(df_1m[\"ltp\"], errors=\"coerce\").dropna().astype(float)\n",
    "ret_1m  = close.pct_change().dropna()\n",
    "\n",
    "# ── 2) 5-minute returns for clustering check ─────────────────\n",
    "ret_5m  = close.resample(\"5min\").last().pct_change().dropna()\n",
    "lb5_p   = acorr_ljungbox(ret_5m**2, lags=[1], return_df=True)[\"lb_pvalue\"].iloc[0]\n",
    "\n",
    "# ── 3) Stationarity on 1-min returns ─────────────────────────\n",
    "WINDOW = 250\n",
    "adf_p  = ret_1m.rolling(WINDOW).apply(lambda x: adfuller(x, maxlag=12)[1], raw=False)\n",
    "kpss_p = ret_1m.rolling(WINDOW).apply(lambda x: kpss(x, nlags=\"auto\")[1], raw=False)\n",
    "\n",
    "# ── 4) Heavy tails (1-min) ───────────────────────────────────\n",
    "kurt_ex   = ret_1m.rolling(WINDOW).apply(\n",
    "    lambda x: kurtosis(x, fisher=True, bias=False), raw=False\n",
    ")\n",
    "tail       = ret_1m.abs().sort_values(ascending=False)\n",
    "k          = max(int(0.05 * len(tail)), 1)\n",
    "hill_alpha = k / np.log(tail.iloc[:k] / tail.iloc[k-1]).sum()\n",
    "\n",
    "# ── 5) Vol-persistence (Hurst of 5-min RV) ───────────────────\n",
    "rv_5m = ret_5m.rolling(12).std().dropna()   # 1-hour window\n",
    "H, *_ = compute_Hc(rv_5m, kind=\"change\", simplified=True)\n",
    "\n",
    "# ── 6) Structural breaks (1-min) ─────────────────────────────\n",
    "n_breaks = len(rpt.Binseg(\"l2\").fit(ret_1m.values).predict(pen=10)) - 1\n",
    "\n",
    "# ── 7) Summary table ─────────────────────────────────────────\n",
    "summary = pd.Series({\n",
    "    \"ADF pass-fraction\"     : (adf_p  < 0.05).mean(),\n",
    "    \"KPSS pass-fraction\"    : (kpss_p > 0.05).mean(),\n",
    "    \"LB p-val 5-min lag-1\"  : lb5_p,\n",
    "    \"Kurtosis>2 fraction\"   : (kurt_ex > 2).mean(),\n",
    "    \"Hill alpha\"            : hill_alpha,\n",
    "    \"Hurst (rv-5m)\"         : H,\n",
    "    \"Breakpoints\"           : n_breaks\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# ── 8) Gate criteria ─────────────────────────────────────────\n",
    "gate_pass = (\n",
    "    summary[\"ADF pass-fraction\"]  >= 0.70    and\n",
    "    summary[\"KPSS pass-fraction\"] >= 0.70    and\n",
    "    summary[\"LB p-val 5-min lag-1\"] < 0.05   and  # new clustering rule\n",
    "    (summary[\"Kurtosis>2 fraction\"] > 0.30 or summary[\"Hill alpha\"] < 4) and\n",
    "    summary[\"Hurst (rv-5m)\"] > 0.55\n",
    ")\n",
    "\n",
    "print(\"\\nMARKET-DYNAMICS  GATE:\", \"PASS ✅\" if gate_pass else \"FAIL ❌\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Key facts from the final diagnostics\n",
    "\n",
    "# Metric\tValue\tVerdict\n",
    "# ADF pass-fraction\t0.99\t✔︎ returns are mean-stationary\n",
    "# KPSS pass-fraction\t0.96\t✔︎ no deterministic trend\n",
    "# 5-min LB p-val (lag-1)\t7.5 × 10⁻⁸\t✔︎ strong volatility clustering at 5 min\n",
    "# Kurtosis > 2 windows\t0.73\t✔︎ persistent fat-tails\n",
    "# Hill tail-α\t2.98\t✔︎ heavy tails, sub-Gaussian\n",
    "# Hurst (5-min RV)\t0.70\t✔︎ long-memory in volatility\n",
    "# Structural breaks\t0\tno large global regime breaks\n",
    "\n",
    "# Interpretation\n",
    "\n",
    "# Minute data are noise-like, but as soon as we smooth to 5-minute bars, classic ARCH-style clustering appears immediately (lag-1).\n",
    "\n",
    "# Volatility is both persistent (H ≈ 0.70) and fat-tailed (α ≈ 3) — justifies a latent-vol regime model plus tail-aware risk shell.\n",
    "\n",
    "# No big structural breaks means one walk-forward timetable (e.g., yearly) is safe; no need for hard epoch splits.\n",
    "\n",
    "\n",
    "# Design decisions locked in\n",
    "# Component\tSetting\n",
    "# Feature sampling\tUse 5-minute realised-vol (rv_5m) as HMM input.\n",
    "# Clustering feature\tInclude 5-min lag-1 AC of\n",
    "# Risk shell\tStops scaled with fat-tail statistics (α ≈ 3).\n",
    "# Walk-forward folds\tTime-based (calendar years) without extra breakpoints.\n",
    "\n",
    "# With the data profile crystal-clear, we can now advance to Fractal-Persistence Stability (rolling Hurst on price series) and then build the HMM vol-regime model using these 5-minute features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fractal-Persistence Module — rolling Hurst on price & volatility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaNs in 5-min close after ffill: 0.00%\n",
      "\n",
      "Series ready:\n",
      "  close_1m  → 38,458 rows\n",
      "  close_5m  → 7,774 rows\n",
      "  rv_5m     → 7,774 rows\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "#  CELL ①  –  PREP   (works even with sparse tick data)\n",
    "# ======================================================\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# ---- 1. 1-minute close series ----------------------------------------\n",
    "close_1m = (\n",
    "    pd.to_numeric(df_1m[\"ltp\"], errors=\"coerce\")   # df_1m already in memory\n",
    "      .dropna()\n",
    "      .astype(float)\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "assert close_1m.index.is_monotonic_increasing, \"1-min index not monotonic\"\n",
    "assert close_1m.index.tz is not None,          \"timestamps must be tz-aware\"\n",
    "\n",
    "# ---- 2. Restrict to trading session (09:15–15:30 IST) ----------------\n",
    "mkt_1m = close_1m.between_time(\"09:15\", \"15:30\")\n",
    "\n",
    "# ---- 3. Helper: forward-fill gaps only *within* each day -------------\n",
    "def resample_ffill(session_series: pd.Series, freq=\"5min\") -> pd.Series:\n",
    "    parts = []\n",
    "    for _, sub in session_series.groupby(session_series.index.date):\n",
    "        parts.append(\n",
    "            sub.resample(freq).last().ffill()     # last price → ffill intraday\n",
    "        )\n",
    "    return pd.concat(parts)\n",
    "\n",
    "# ---- 4. 5-minute close  ----------------------------------------------\n",
    "close_5m = resample_ffill(mkt_1m, \"5min\")\n",
    "\n",
    "# ---- 5. 5-minute realised volatility ---------------------------------\n",
    "# (std of 5 successive 1-min returns, aligned & ffilled like price)\n",
    "rv_raw  = mkt_1m.pct_change().rolling(5).std()\n",
    "rv_5m   = resample_ffill(rv_raw.dropna(), \"5min\").reindex(close_5m.index)\n",
    "\n",
    "# ---- 6. Sanity checks -------------------------------------------------\n",
    "gap_ratio = close_5m.isna().mean()\n",
    "print(f\"Remaining NaNs in 5-min close after ffill: {gap_ratio:.2%}\")\n",
    "assert gap_ratio < 0.01, \"Still too many gaps after forward-fill (<1 % required)\"\n",
    "\n",
    "print(\"\\nSeries ready:\"\n",
    "      f\"\\n  close_1m  → {len(close_1m):,} rows\"\n",
    "      f\"\\n  close_5m  → {len(close_5m):,} rows\"\n",
    "      f\"\\n  rv_5m     → {len(rv_5m):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H(price-5m): 100%|██████████| 1530/1530 [00:00<00:00, 2341.09it/s]\n",
      "H(rv-5m): 100%|██████████| 1530/1530 [00:00<00:00, 2450.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaN ratio after rolling-H:\n",
      "  hurst_price_5m: 0.01595060457936712\n",
      "  hurst_rv_5m   : 0.01659377411885773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boot CI: 100%|██████████| 1555/1555 [00:31<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final feature frame shape: (7645, 4)\n",
      "NaN check per column:\n",
      " timestamp         0.0\n",
      "hurst_price_5m    0.0\n",
      "hurst_rv_5m       0.0\n",
      "hurst_regime      0.0\n",
      "dtype: float64\n",
      "\n",
      "Saved → features/regime_features.csv\n",
      "Average 90 % CI width on H(5-min price): 0.059\n",
      "FRACTAL-PERSISTENCE GATE: PASS ✅\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "#  CELL ②  –  Fractal-Persistence diagnostics  (NaN-safe, fast)\n",
    "# ===================================================================\n",
    "import numpy as np, pandas as pd, warnings, os\n",
    "from hurst import compute_Hc\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")\n",
    "\n",
    "# ───────── helper: DFA Hurst, tolerant to zeros & NaNs ──────────────\n",
    "def hurst_dfa_safe(arr: np.ndarray) -> float:\n",
    "    if np.isnan(arr).any() or np.allclose(arr.max() - arr.min(), 0):\n",
    "        return np.nan\n",
    "    h, *_ = compute_Hc(arr + 1e-8, kind=\"change\", simplified=True)\n",
    "    return float(h)\n",
    "\n",
    "def rolling_hurst(series: pd.Series, window: int, tag: str,\n",
    "                  step: int = 5) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute H every <step> windows; NaN if slice has NaNs or flat.\n",
    "    Then forward-fill to full index.\n",
    "    \"\"\"\n",
    "    idx_out, vals = [], []\n",
    "    arr = series.values\n",
    "    for i in tqdm(range(window, len(arr) + 1, step), desc=f\"H({tag})\"):\n",
    "        vals.append(hurst_dfa_safe(arr[i-window:i]))\n",
    "        idx_out.append(series.index[i-1])\n",
    "    coarse = pd.Series(vals, index=idx_out)\n",
    "    return coarse.reindex(series.index, method=\"ffill\")\n",
    "\n",
    "# ───────── parameters ───────────────────────────────────────────────\n",
    "WIN_5M, STEP, BOOT_N = 125, 5, 50   # 2-day window, 25-min stride, 50 bootstraps\n",
    "\n",
    "# ───────── rolling H on 5-min price & RV ────────────────────────────\n",
    "H_5m = rolling_hurst(close_5m, WIN_5M, \"price-5m\", STEP).rename(\"hurst_price_5m\")\n",
    "H_rv = rolling_hurst(rv_5m,    WIN_5M, \"rv-5m\",    STEP).rename(\"hurst_rv_5m\")\n",
    "\n",
    "print(\"\\nNaN ratio after rolling-H:\")\n",
    "print(\"  hurst_price_5m:\", H_5m.isna().mean())\n",
    "print(\"  hurst_rv_5m   :\", H_rv.isna().mean())\n",
    "\n",
    "# ───────── light bootstrap 90 % CI on price-H ───────────────────────\n",
    "ci_lo, ci_hi = [], []\n",
    "for ts in tqdm(H_5m.index[::STEP], desc=\"Boot CI\"):\n",
    "    win = close_5m.loc[ts - pd.Timedelta(minutes=5*(WIN_5M-1)): ts]\n",
    "    boots = [hurst_dfa_safe(np.random.choice(win.values, size=WIN_5M, replace=True))\n",
    "             for _ in range(BOOT_N)]\n",
    "    lo, hi = np.nanpercentile(boots, [5, 95])\n",
    "    ci_lo.append(lo); ci_hi.append(hi)\n",
    "\n",
    "ci_lo = pd.Series(ci_lo, index=H_5m.index[::STEP]).reindex(H_5m.index, method=\"ffill\")\n",
    "ci_hi = pd.Series(ci_hi, index=H_5m.index[::STEP]).reindex(H_5m.index, method=\"ffill\")\n",
    "ci_width = (ci_hi - ci_lo).mean()\n",
    "\n",
    "# ───────── regime label & feature frame ─────────────────────────────\n",
    "label  = lambda h: \"AP\" if h < 0.45 else (\"P\" if h > 0.55 else \"Noise\")\n",
    "regime = H_5m.apply(label).rename(\"hurst_regime\")\n",
    "\n",
    "feat = (\n",
    "    pd.concat([H_5m, H_rv, regime], axis=1)\n",
    "      .dropna()                              # drop rows with any NaNs\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"timestamp\"})\n",
    ")\n",
    "\n",
    "print(\"\\nFinal feature frame shape:\", feat.shape)\n",
    "print(\"NaN check per column:\\n\", feat.isna().mean())\n",
    "\n",
    "# ───────── export clean CSV ─────────────────────────────────────────\n",
    "os.makedirs(\"features\", exist_ok=True)\n",
    "feat.to_csv(\"features/regime_features.csv\", index=False, float_format=\"%.6f\")\n",
    "print(\"\\nSaved → features/regime_features.csv\")\n",
    "\n",
    "# ───────── gate decision ────────────────────────────────────────────\n",
    "gate_pass = (\n",
    "    ci_width < 0.10\n",
    "    and (feat[\"hurst_regime\"] == \"AP\").mean() > 0.10\n",
    "    and (feat[\"hurst_regime\"] == \"P\").mean()  > 0.10\n",
    ")\n",
    "\n",
    "print(f\"Average 90 % CI width on H(5-min price): {ci_width:.3f}\")\n",
    "print(\"FRACTAL-PERSISTENCE GATE:\", \"PASS ✅\" if gate_pass else \"FAIL ❌\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
